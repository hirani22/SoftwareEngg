{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EquationSolver.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hirani22/SoftwareEngg/blob/main/EquationSolver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrS-ve46MgSl"
      },
      "source": [
        "**HANDWRITTEN EQUATION SOLVER USING CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYlp5uj7Hj8c"
      },
      "source": [
        "Importing Reqd Libraries and tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDBPzuyDpXej"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "#converts the numpy values to binary\n",
        "import seaborn as sns"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdLTcZ8UqiXW"
      },
      "source": [
        "np.random.seed(2)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EqR1CVPHpuk"
      },
      "source": [
        "Uploading and Extracting Dataset using Google Drive.\n",
        "Dataset has been downloaded from MNIST dataset and consists of approximately 85k images for raw dataset. Each image is 28x28 pixels. They have been encoded as 10 (/), 11(+),12(-), 13(*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZu-qSHjr39E"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS5y_utfupL3",
        "outputId": "4db94b87-5b0d-4a20-a19a-ba62788cd5a2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MSk5tWavVuC"
      },
      "source": [
        "dataset=pd.read_csv('/content/drive/MyDrive/Netra Hirani/EquationSolver_dataset.csv')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw0byrbGwlxS"
      },
      "source": [
        "#creating label\n",
        "y = dataset[\"label\"]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q45-tfmwpQU"
      },
      "source": [
        "#dropping label\n",
        "X = dataset.drop(labels = [\"label\"], axis = 1)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hOX7Oa0wywU"
      },
      "source": [
        "#deleting dataset to reduce memory usage\n",
        "del dataset"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "5huphi7dwzns",
        "outputId": "34e52b74-ad33-43ae-904f-961275be2781"
      },
      "source": [
        "#visualizing the dataset\n",
        "g = sns.countplot(y)\n",
        "y.value_counts()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11    22164\n",
              "12    21387\n",
              "1      4684\n",
              "7      4401\n",
              "3      4351\n",
              "9      4188\n",
              "2      4177\n",
              "6      4137\n",
              "0      4132\n",
              "4      4072\n",
              "8      4063\n",
              "5      3795\n",
              "13       80\n",
              "10       78\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cU5jG80w1VO"
      },
      "source": [
        "#Grayscale normalization to reduce the effect of illumination differences.\n",
        "#Grayscale normalization is used to bring all the images with intensity values into a specific range \n",
        "X = X / 255.0"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIGORT7Uw4rQ"
      },
      "source": [
        "#reshaping the dataset [size, height, width, channels = 1 due to grayscale].\n",
        "X = X.values.reshape(-1,28,28,1)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KLFduJzw5iX"
      },
      "source": [
        "#categorical conversion of label\n",
        "y = to_categorical(y, num_classes = 14)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz1E_cEGw7R1"
      },
      "source": [
        "#90% Training and 10% Validation split\n",
        "random_seed = 2\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1 , random_state = random_seed, stratify = y)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTQuDi2ZJAcV"
      },
      "source": [
        "Building CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1EAatTDw9z_"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "#Conv2D filters extend through the three channels in an image (Red, Green, and Blue). \n",
        "#The filters may be different for each channel too.\n",
        "#Max pooling selects the brighter pixels from the image.\n",
        "from tensorflow.keras.optimizers import RMSprop #rootmeansquare\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau #reduce learning rate\n",
        "#This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, \n",
        "#the learning rate is reduced.\n",
        "from tensorflow import keras"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEcABHO7xADj"
      },
      "source": [
        "#creating the instance of the model\n",
        "model = Sequential()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGrbtbh9xDGR"
      },
      "source": [
        "#adding layers to the model\n",
        "#Layer: 1\n",
        "#Mandatory Conv2D parameter is the numbers of filters that convolutional layers will learn from.\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = \"Same\", activation = \"relu\", input_shape = (28, 28, 1)))\n",
        "#we are learning from 32 filters, kernel size is specifying the height and width of the convolution window\n",
        "#activation is simply here for convenience stating which activation will be performed after convolution \n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = \"Same\", activation = \"relu\"))\n",
        "model.add(MaxPool2D(pool_size = (2,2)))\n",
        "#maxpool is here to reduce the spatial dimensions of the output\n",
        "model.add(Dropout(0.25))\n",
        "#dropout for regularization. i.e. prevent overfitting"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4qJeYdixFCd"
      },
      "source": [
        "#Layer: 2\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
        "model.add(MaxPool2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.25))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm3eRFSqxHXy"
      },
      "source": [
        "#fully connected layer and output\n",
        "model.add(Flatten())\n",
        "#flattens multi-dimensional output to single dimension\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "#fully connected layer. Sort of adds a hidden layer and neuron by neuron collectively passes to the o/p layer\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(14, activation = \"softmax\"))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSO_8lU0xI81",
        "outputId": "042ad392-54af-42b8-ec1c-7f58544e15c0"
      },
      "source": [
        "#Set the optimizer\n",
        "optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay=0.0 )\n",
        "\n",
        "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor = \"val_accuracy\",\n",
        "                                            patience = 3,\n",
        "                                            verbose = 1,\n",
        "                                            factor = 0.5,\n",
        "                                            min_lr = 0.0001)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gESU7c4KxLGP"
      },
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "f882x0fbxPWq",
        "outputId": "dc47ab55-5b61-40b9-c268-76f4fd67f366"
      },
      "source": [
        "datagen.fit(X_train)\n",
        "#fitting the model\n",
        "epochs = 5\n",
        "batch_size = 86\n",
        "\n",
        "history = model.fit_generator(\n",
        "                                datagen.flow(X_train,y_train, batch_size=batch_size),\n",
        "                                epochs = epochs, #An epoch is an iteration over the entire x and y data provided\n",
        "                                validation_data = (X_val,y_val), #Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
        "                                verbose = 2, #output\n",
        "                                steps_per_epoch=X_train.shape[0] // batch_size,  # Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch.\n",
        "                                callbacks=[learning_rate_reduction]                            \n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "896/896 - 505s - loss: 0.2911 - accuracy: 0.9098 - val_loss: 0.0491 - val_accuracy: 0.9870\n",
            "Epoch 2/5\n",
            "896/896 - 505s - loss: 0.0805 - accuracy: 0.9760 - val_loss: 0.0323 - val_accuracy: 0.9905\n",
            "Epoch 3/5\n",
            "896/896 - 505s - loss: 0.0634 - accuracy: 0.9817 - val_loss: 0.0386 - val_accuracy: 0.9887\n",
            "Epoch 4/5\n",
            "896/896 - 504s - loss: 0.0567 - accuracy: 0.9835 - val_loss: 0.0331 - val_accuracy: 0.9915\n",
            "Epoch 5/5\n",
            "896/896 - 502s - loss: 0.0560 - accuracy: 0.9845 - val_loss: 0.0340 - val_accuracy: 0.9914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3oQckACLuFq"
      },
      "source": [
        "We need to save the model before we continue to later deploy and apply. We plan to do so using a .h5 extension since HDF5 uses a \"file directory\" like structure that allows you to organize data within the file in many different structured ways."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afbo7wuFCwuO"
      },
      "source": [
        "from PIL import Image\n",
        "#PIL is Python Imaging Library\n",
        "from itertools import groupby\n",
        "#itertools are fast, memory-efficient tools\n",
        "#groupby- This method calculates the keys for each element present in iterable. "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYmZIiY9C6AV"
      },
      "source": [
        "image = Image.open(\"/content/drive/MyDrive/Netra Hirani/testing.png\").convert(\"L\")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UXLH6ScD7VY"
      },
      "source": [
        "#resizing to 28 height pixels\n",
        "w = image.size[0]\n",
        "h = image.size[1]\n",
        "r = w / h # aspect ratio\n",
        "new_w = int(r * 28)\n",
        "new_h = 28\n",
        "new_image = image.resize((new_w, new_h))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlEFNn6SD8cD"
      },
      "source": [
        "#converting to a numpy array\n",
        "new_image_arr = np.array(new_image)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et6DVoj1D_WU"
      },
      "source": [
        "#inverting the image to make background = 0\n",
        "new_inv_image_arr = 255 - new_image_arr"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EA9OJm3EBxt"
      },
      "source": [
        "#rescaling the image\n",
        "final_image_arr = new_inv_image_arr / 255.0"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LGkFBz1ME_F"
      },
      "source": [
        "Further OCR and parsing of the image needs to be done. We need to resize then and then finally predict the uploaded equation before sending it to the multidigit calculator. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjrUjJ1txRjf"
      },
      "source": [
        "#mathematical operations\n",
        "def math_expression_generator(arr):\n",
        "    \n",
        "    op = {\n",
        "              10,   # = \"/\"\n",
        "              11,   # = \"+\"\n",
        "              12,   # = \"-\"\n",
        "              13    # = \"*\"\n",
        "                  }   \n",
        "    \n",
        "    m_exp = []\n",
        "    temp = []\n",
        "        \n",
        "    #creating a list separating all elements\n",
        "    for item in arr:\n",
        "        if item not in op:\n",
        "            temp.append(item)\n",
        "        else:\n",
        "            m_exp.append(temp)\n",
        "            m_exp.append(item)\n",
        "            temp = []\n",
        "    if temp:\n",
        "        m_exp.append(temp)\n",
        "        \n",
        "    #converting the elements to numbers and operators\n",
        "    i = 0\n",
        "    num = 0\n",
        "    for item in m_exp:\n",
        "        if type(item) == list:\n",
        "            if not item:\n",
        "                m_exp[i] = \"\"\n",
        "                i = i + 1\n",
        "            else:\n",
        "                num_len = len(item)\n",
        "                for digit in item:\n",
        "                    num_len = num_len - 1\n",
        "                    num = num + ((10 ** num_len) * digit)\n",
        "                m_exp[i] = str(num)\n",
        "                num = 0\n",
        "                i = i + 1\n",
        "        else:\n",
        "            m_exp[i] = str(item)\n",
        "            m_exp[i] = m_exp[i].replace(\"10\",\"/\")\n",
        "            m_exp[i] = m_exp[i].replace(\"11\",\"+\")\n",
        "            m_exp[i] = m_exp[i].replace(\"12\",\"-\")\n",
        "            m_exp[i] = m_exp[i].replace(\"13\",\"*\")\n",
        "            \n",
        "            i = i + 1\n",
        "    \n",
        "    #joining the list of strings to create the mathematical expression\n",
        "    separator = ' '\n",
        "    m_exp_str = separator.join(m_exp)\n",
        "    \n",
        "    return (m_exp_str)\n",
        "\n",
        "#creating the mathematical expression\n",
        "    m_exp_str = math_expression_generator(elements_pred)\n",
        "\n",
        "    'calculating the mathematical expression using eval()'\n",
        "    while True:\n",
        "      try:\n",
        "        answer = eval(m_exp_str)    #evaluating the answer\n",
        "        answer = round(answer, 2)\n",
        "        equation  = m_exp_str + \" = \" + str(answer)\n",
        "        print(equation)   #printing the equation\n",
        "        break\n",
        "\n",
        "      except SyntaxError:\n",
        "        print(\"Invalid predicted expression!!\")\n",
        "        print(\"Following is the predicted expression:\")\n",
        "        print(m_exp_str)\n",
        "        break"
      ],
      "execution_count": 50,
      "outputs": []
    }
  ]
}